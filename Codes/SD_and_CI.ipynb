{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "GDV"
      ],
      "metadata": {
        "id": "f1E2OeBORsG2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ECb78Go_mEqO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Assuming you have already defined the computeGDV function in your code\n",
        "# ROUTINES FOR COMPUTING THE GENERAL DISCRIMINATION VALUE\n",
        "\n",
        "'''\n",
        "The routine cmpGDV(dta,lab) expects\n",
        "  a matrix of data (rows = data vectors) and\n",
        "  a vector of corresponding labels.\n",
        "\n",
        "It returns\n",
        "  the mean intra-cluster distance,\n",
        "  the mean inter-cluster distance, and\n",
        "  the gdv-value\n",
        "'''\n",
        "\n",
        "# ***** IMPORTS ****************************************************************\n",
        "\n",
        "from numpy import unique, concatenate, zeros\n",
        "from numpy import isnan, isinf, sum, sqrt, array, triu\n",
        "from numpy.random import seed, multivariate_normal\n",
        "from scipy.spatial import distance\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def makeGDVData(dta,lab):\n",
        "  res = []\n",
        "  labels = unique(lab)\n",
        "  for L in labels:\n",
        "    res.append( dta[ lab==L ] )\n",
        "  return res\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def zScoreSpecial(data):\n",
        "\n",
        "  # get parameters\n",
        "  NC = len(data) # nr. of clusters\n",
        "  ND = data[0].shape[1] # nr. of dimensions\n",
        "\n",
        "  # copy data --> zData\n",
        "  zData = []\n",
        "  for C in range(NC):\n",
        "    arr = data[C].copy()\n",
        "    zData.append(arr)\n",
        "\n",
        "  # compute means and STDs for each dimension, over ALL data\n",
        "  all = concatenate(zData)\n",
        "  mu =  zeros(shape=ND, dtype=float)\n",
        "  sig = zeros(shape=ND, dtype=float)\n",
        "  for D in range(ND):\n",
        "    mu[D]  = all[:,D].mean()\n",
        "    sig[D] = all[:,D].std()\n",
        "\n",
        "  # z-score the data in each cluster\n",
        "  for C in range(NC):\n",
        "    for D in range(ND):\n",
        "      zData[C][:,D] = ( zData[C][:,D] - mu[D] ) / ( 2 * sig[D] )\n",
        "\n",
        "  # replace nan and inf by 0\n",
        "  for C in range(NC):\n",
        "    nanORinf = isnan(zData[C]) | isinf(zData[C])\n",
        "    zData[C][ nanORinf ] = 0.0\n",
        "\n",
        "  return zData\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def computeGDV(data):\n",
        "\n",
        "  '''\n",
        "  Returns the Generalized Discrimination Value\n",
        "  as well as intraMean and interMean\n",
        "\n",
        "  data is expected to be a list of label-sorted point 'clusters':\n",
        "  data = [cluster1, cluster2, ...]\n",
        "\n",
        "  Each cluster is a NumPy matrix,\n",
        "  and the rows of this matrix\n",
        "  are n-dimensional data vectors,\n",
        "  each belonging to the same label.\n",
        "  '''\n",
        "\n",
        "  # get parameters\n",
        "  NC = len(data) # nr. of clusters\n",
        "  ND = data[0].shape[1] # nr. of dimensions\n",
        "\n",
        "  # copy data --> zData\n",
        "  zData = []\n",
        "  for C in range(NC):\n",
        "    arr = data[C].copy()\n",
        "    zData.append(arr)\n",
        "\n",
        "  # dimension-wise z-scoring\n",
        "  zData = zScoreSpecial(zData)\n",
        "\n",
        "  # intra-cluster distances\n",
        "  dIntra = zeros(shape=NC, dtype=float)\n",
        "  for C in range(NC):\n",
        "    NP = zData[C].shape[0]\n",
        "    dis = distance.cdist(zData[C], zData[C], 'euclidean')\n",
        "    # dis is symmetric with zero diagonal\n",
        "    dIntra[C] = sum(dis) / (NP*(NP-1)) # divide by nr. of non-zero el.\n",
        "  #print('dIntra = ',dIntra)\n",
        "\n",
        "  # inter-cluster distances\n",
        "  dInter = zeros(shape=(NC,NC), dtype=float)\n",
        "  for C1 in range(NC):\n",
        "    NP1 = zData[C1].shape[0]\n",
        "    for C2 in range(NC):\n",
        "      NP2 = zData[C2].shape[0]\n",
        "      dis = distance.cdist(zData[C1], zData[C2], 'euclidean')\n",
        "      dInter[C1][C2] = sum(dis) / (NP1*NP2) # divide by nr. of non-zero el.\n",
        "  #print('dInter =\\n',dInter)\n",
        "\n",
        "  # compute GDV\n",
        "  pre = 1.0 / sqrt(float(ND))\n",
        "  intraMean = dIntra.mean()\n",
        "  interMean = sum( triu(dInter,k=1) ) / (NC*(NC-1)/2) # divide by nr. of non-zero el.\n",
        "  #print('intraMean=',intraMean,'\\ninterMean=',interMean)\n",
        "  gdv = pre * (intraMean - interMean)\n",
        "\n",
        "  return pre*intraMean, pre*interMean,gdv\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def cmpGDV(dta,lab):\n",
        "  gdvData = makeGDVData(dta,lab)\n",
        "  intraMean,interMean,gdv = computeGDV(gdvData)\n",
        "  return intraMean,interMean,gdv\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def TestGDV():\n",
        "\n",
        "  # TEST 1\n",
        "\n",
        "  # generate first cluster\n",
        "  mean = array([0.0, 0.0])\n",
        "  cov = array([[0.04, 0.0 ],\n",
        "               [0.0 , 0.04]])\n",
        "  seed(978820)\n",
        "  cluster1 =  multivariate_normal(mean,cov,1000)\n",
        "  print(cluster1)\n",
        "\n",
        "  # generate second cluster\n",
        "  mean = array([1.0, 1.0])\n",
        "  cov = array([[0.04, 0.0 ],\n",
        "               [0.0 , 0.04]])\n",
        "  seed(978820)\n",
        "  cluster2 =  multivariate_normal(mean,cov,1000)\n",
        "\n",
        "  # data = list of clusters\n",
        "  data = []\n",
        "  data.append(cluster1)\n",
        "  data.append(cluster2)\n",
        "  #Plot2D(data,0,1,'case1.png')\n",
        "\n",
        "  # compute GDV\n",
        "  intraMean,interMean,gdv = computeGDV(data)\n",
        "  print('GDV = ',gdv)\n",
        "\n",
        "  # TEST 2\n",
        "\n",
        "  # generate first cluster\n",
        "  mean = array([0.0, 0.0])\n",
        "  cov = array([[1.0, 0.0 ],\n",
        "               [0.0 ,1.0]])\n",
        "  seed(978820)\n",
        "  cluster1 =  multivariate_normal(mean,cov,1000)\n",
        "\n",
        "  # generate second cluster\n",
        "  mean = array([1.0, 1.0])\n",
        "  cov = array([[1.0, 0.0 ],\n",
        "               [0.0 , 1.0]])\n",
        "  seed(978820)\n",
        "  cluster2 =  multivariate_normal(mean,cov,1000)\n",
        "\n",
        "  # data = list of clusters\n",
        "  data = []\n",
        "  data.append(cluster1)\n",
        "  data.append(cluster2)\n",
        "  #Plot2D(data,0,1,'case1.png')\n",
        "\n",
        "  # compute GDV\n",
        "  intraMean,interMean,gdv = computeGDV(data)\n",
        "  print('GDV = ',gdv)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data"
      ],
      "metadata": {
        "id": "gQi4PgjmRzyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# List of .npz file paths (layers 1-12)/ for the CxG-bert only change the paths in \"file_paths\".\n",
        "file_paths = [\n",
        "    'BERT-base_layer_01.npz',\n",
        "    'BERT-base_layer_02.npz',\n",
        "    'BERT-base_layer_03.npz',\n",
        "    'BERT-base_layer_04.npz',\n",
        "    'BERT-base_layer_05.npz',\n",
        "    'BERT-base_layer_06.npz',\n",
        "    'BERT-base_layer_07.npz',\n",
        "    'BERT-base_layer_08.npz',\n",
        "    'BERT-base_layer_09.npz',\n",
        "    'BERT-base_layer_10.npz',\n",
        "    'BERT-base_layer_11.npz',\n",
        "    'BERT-base_layer_12.npz'\n",
        "]\n",
        "\n",
        "# Loop through each file and check what it contains\n",
        "for file in file_paths:\n",
        "    print(f\"\\n--- {file} ---\")\n",
        "    data = np.load(file)\n",
        "    print(\"Keys:\", data.files)   # list of array names stored in the file\n",
        "    for key in data.files:\n",
        "        arr = data[key]\n",
        "        print(f\"  {key}: shape={arr.shape}, dtype={arr.dtype}\")"
      ],
      "metadata": {
        "id": "5MtDf5nymIOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Robustness"
      ],
      "metadata": {
        "id": "-AaX-k6nR3Mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "\n",
        "\n",
        "def zscore_special_matrix(X):\n",
        "    \"\"\"Z-score matching your GDV definition: (x - mu) / (2*sigma)\"\"\"\n",
        "    mu = X.mean(axis=0)\n",
        "    sig = X.std(axis=0)\n",
        "    Z = (X - mu) / (2.0 * (sig + 1e-12))\n",
        "    Z[~np.isfinite(Z)] = 0.0\n",
        "    return Z\n",
        "\n",
        "def gdv_from_distance_matrix(D, y, ndims):\n",
        "    \"\"\"Compute GDV from distance matrix\"\"\"\n",
        "    pre = 1.0 / np.sqrt(float(ndims))\n",
        "    classes = np.unique(y)\n",
        "    k = len(classes)\n",
        "\n",
        "    # Intra-cluster means\n",
        "    intra_vals = []\n",
        "    for c in classes:\n",
        "        idx = np.where(y == c)[0]\n",
        "        if len(idx) < 2:\n",
        "            continue\n",
        "        d_sub = D[np.ix_(idx, idx)]\n",
        "        n = len(idx)\n",
        "        tri = d_sub[np.triu_indices(n, k=1)]\n",
        "        intra_vals.append(tri.mean() if tri.size > 0 else 0.0)\n",
        "    intra_mean = np.mean(intra_vals) if len(intra_vals) > 0 else 0.0\n",
        "\n",
        "    # Inter-cluster mean\n",
        "    inter_vals = []\n",
        "    for i in range(k):\n",
        "        for j in range(i+1, k):\n",
        "            idx_i = np.where(y == classes[i])[0]\n",
        "            idx_j = np.where(y == classes[j])[0]\n",
        "            if len(idx_i) == 0 or len(idx_j) == 0:\n",
        "                continue\n",
        "            block = D[np.ix_(idx_i, idx_j)]\n",
        "            inter_vals.append(block.mean())\n",
        "    inter_mean = np.mean(inter_vals) if len(inter_vals) > 0 else 0.0\n",
        "\n",
        "    gdv = pre * (intra_mean - inter_mean)\n",
        "    return pre*intra_mean, pre*inter_mean, gdv\n",
        "\n",
        "def observed_gdv(X, y):\n",
        "    \"\"\"Compute observed GDV\"\"\"\n",
        "    ndims = X.shape[1]\n",
        "    Z = zscore_special_matrix(X)\n",
        "    D = squareform(pdist(Z, metric='euclidean'))\n",
        "    return gdv_from_distance_matrix(D, y, ndims), D\n",
        "\n",
        "def load_family_from_npz(npz_path, keys_in_family):\n",
        "    \"\"\"Load embeddings for a verb family\"\"\"\n",
        "    d = np.load(npz_path)\n",
        "    X_list, y_list, names = [], [], []\n",
        "    label_id = 0\n",
        "    for key in keys_in_family:\n",
        "        if key in d.files:\n",
        "            Xi = d[key]\n",
        "            X_list.append(Xi)\n",
        "            y_list.append(np.full(len(Xi), label_id, dtype=int))\n",
        "            names.append(key)\n",
        "            label_id += 1\n",
        "    if label_id < 2:\n",
        "        return None, None, names\n",
        "    X = np.vstack(X_list)\n",
        "    y = np.concatenate(y_list)\n",
        "    return X, y, names\n",
        "\n",
        "# ============================================================\n",
        "# Bootstrap CI for GDV\n",
        "# ============================================================\n",
        "\n",
        "def bootstrap_gdv_ci(X, y, n_boot=1000, ci=95, seed=42):\n",
        "    \"\"\"Bootstrap resample to estimate CI on GDV\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    n = X.shape[0]\n",
        "    ndims = X.shape[1]\n",
        "\n",
        "    gdv_boots = np.empty(n_boot, dtype=float)\n",
        "    for b in range(n_boot):\n",
        "        idx = rng.choice(n, size=n, replace=True)\n",
        "        Xb, yb = X[idx], y[idx]\n",
        "        Z = zscore_special_matrix(Xb)\n",
        "        D = squareform(pdist(Z, metric='euclidean'))\n",
        "        _, _, gdv_b = gdv_from_distance_matrix(D, yb, ndims)\n",
        "        gdv_boots[b] = gdv_b\n",
        "\n",
        "    alpha = (100 - ci) / 2.0\n",
        "    lower = np.percentile(gdv_boots, alpha)\n",
        "    upper = np.percentile(gdv_boots, 100 - alpha)\n",
        "    mean = np.mean(gdv_boots)\n",
        "\n",
        "    return mean, lower, upper, gdv_boots\n",
        "\n",
        "# ============================================================\n",
        "# Main analysis\n",
        "# ============================================================\n",
        "\n",
        "file_paths = [f'BERT-base_layer_{i:02d}.npz' for i in range(1, 13)]\n",
        "\n",
        "groups = {\n",
        "    \"agree\": ['agree_on', 'agree_with', 'agree_that', 'agree_to'],\n",
        "    \"come\":  ['come_back', 'come_in', 'come_out'],\n",
        "    \"give\":  ['give_up', 'give_in', 'give_out', 'give_away'],\n",
        "    \"all\":   ['agree_on', 'agree_with', 'agree_that', 'agree_to',\n",
        "              'come_back', 'come_in', 'come_out',\n",
        "              'give_up', 'give_in', 'give_out', 'give_away'],\n",
        "}\n",
        "\n",
        "N_BOOT = 1000\n",
        "CI_LEVEL = 95\n",
        "results_boot = []\n",
        "\n",
        "for npz_path in file_paths:\n",
        "    layer_name = os.path.basename(npz_path).replace('.npz', '')\n",
        "    # FIX: Extract layer number correctly\n",
        "    layer_idx = int(layer_name.split('_')[2])  # Changed from [1] to [2]\n",
        "\n",
        "    for group_name, family_keys in groups.items():\n",
        "        X, y, class_names = load_family_from_npz(npz_path, family_keys)\n",
        "        if X is None or len(np.unique(y)) < 2:\n",
        "            continue\n",
        "\n",
        "        # Observed GDV\n",
        "        (_, _, gdv_obs), _ = observed_gdv(X, y)\n",
        "\n",
        "        # Bootstrap CI\n",
        "        gdv_mean, gdv_lo, gdv_hi, gdv_boots = bootstrap_gdv_ci(\n",
        "            X, y, n_boot=N_BOOT, ci=CI_LEVEL, seed=42\n",
        "        )\n",
        "        gdv_sd = np.std(gdv_boots)\n",
        "\n",
        "        results_boot.append({\n",
        "            'layer_idx': layer_idx,\n",
        "            'layer': layer_name,\n",
        "            'group': group_name,\n",
        "            'gdv_obs': gdv_obs,\n",
        "            'gdv_boot_mean': gdv_mean,\n",
        "            'gdv_boot_sd': gdv_sd,\n",
        "            'gdv_boot_lower': gdv_lo,\n",
        "            'gdv_boot_upper': gdv_hi,\n",
        "        })\n",
        "\n",
        "        print(f\"{layer_name} | {group_name}: \"\n",
        "              f\"GDV_obs={gdv_obs:.3f}, \"\n",
        "              f\"Boot mean={gdv_mean:.3f}, SD={gdv_sd:.4f}, \"\n",
        "              f\"{CI_LEVEL}% CI=[{gdv_lo:.3f}, {gdv_hi:.3f}]\")\n",
        "\n",
        "# Save results\n",
        "import pandas as pd\n",
        "df_boot = pd.DataFrame(results_boot)\n",
        "df_boot.to_csv(\"CxG-BERT_gdv_bootstrap_ci.csv\", index=False)\n",
        "\n",
        "# ============================================================\n",
        "# Plot with CI and SD\n",
        "# ============================================================\n",
        "\n",
        "os.makedirs(\"plots_with_ci\", exist_ok=True)\n",
        "\n",
        "for group_name in df_boot['group'].unique():\n",
        "    gdf = df_boot[df_boot['group'] == group_name].sort_values('layer_idx')\n",
        "\n",
        "    # Shaded CI plot\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "    ax.plot(gdf['layer_idx'], gdf['gdv_obs'],\n",
        "            marker='o', label='Observed GDV', color='C0')\n",
        "    ax.fill_between(gdf['layer_idx'],\n",
        "                     gdf['gdv_boot_lower'],\n",
        "                     gdf['gdv_boot_upper'],\n",
        "                     alpha=0.3, color='C0',\n",
        "                     label=f'{CI_LEVEL}% Bootstrap CI')\n",
        "    ax.set_xlabel('Layer', fontsize=12)\n",
        "    ax.set_ylabel('GDV', fontsize=12)\n",
        "    ax.set_title(f'GDV across layers — {group_name} (with {CI_LEVEL}% CI)',\n",
        "                 fontsize=13)\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"plots_with_ci/gdv_with_ci_{group_name}.png\", dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "    # Error bar plot\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "    ax.errorbar(gdf['layer_idx'], gdf['gdv_obs'],\n",
        "                yerr=gdf['gdv_boot_sd'],\n",
        "                marker='o', capsize=5, label='Observed GDV ± SD')\n",
        "    ax.set_xlabel('Layer', fontsize=12)\n",
        "    ax.set_ylabel('GDV', fontsize=12)\n",
        "    ax.set_title(f'GDV across layers — {group_name} (with bootstrap SD)',\n",
        "                 fontsize=13)\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"plots_with_ci/gdv_with_sd_{group_name}.png\", dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "print(\"\\n✓ Bootstrap CI/SD analysis complete.\")\n",
        "print(f\"  - CSV: CxG-BERT_gdv_bootstrap_ci.csv\")\n",
        "print(f\"  - Plots: plots_with_ci/ ({len(df_boot['group'].unique())*2} files)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3zoUsT8mH-s",
        "outputId": "b78a4cd5-6c36-403c-b0ad-f684cffe9a3c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT-base_layer_01 | agree: GDV_obs=-0.062, Boot mean=-0.068, SD=0.0023, 95% CI=[-0.073, -0.064]\n",
            "BERT-base_layer_01 | come: GDV_obs=-0.090, Boot mean=-0.096, SD=0.0027, 95% CI=[-0.102, -0.091]\n",
            "BERT-base_layer_01 | give: GDV_obs=-0.098, Boot mean=-0.105, SD=0.0021, 95% CI=[-0.109, -0.100]\n",
            "BERT-base_layer_01 | all: GDV_obs=-0.356, Boot mean=-0.360, SD=0.0013, 95% CI=[-0.363, -0.358]\n",
            "BERT-base_layer_02 | agree: GDV_obs=-0.105, Boot mean=-0.111, SD=0.0028, 95% CI=[-0.116, -0.106]\n",
            "BERT-base_layer_02 | come: GDV_obs=-0.138, Boot mean=-0.144, SD=0.0034, 95% CI=[-0.151, -0.138]\n",
            "BERT-base_layer_02 | give: GDV_obs=-0.163, Boot mean=-0.169, SD=0.0026, 95% CI=[-0.173, -0.163]\n",
            "BERT-base_layer_02 | all: GDV_obs=-0.347, Boot mean=-0.351, SD=0.0015, 95% CI=[-0.354, -0.348]\n",
            "BERT-base_layer_03 | agree: GDV_obs=-0.241, Boot mean=-0.247, SD=0.0043, 95% CI=[-0.255, -0.238]\n",
            "BERT-base_layer_03 | come: GDV_obs=-0.236, Boot mean=-0.241, SD=0.0047, 95% CI=[-0.251, -0.231]\n",
            "BERT-base_layer_03 | give: GDV_obs=-0.305, Boot mean=-0.310, SD=0.0039, 95% CI=[-0.317, -0.302]\n",
            "BERT-base_layer_03 | all: GDV_obs=-0.408, Boot mean=-0.411, SD=0.0020, 95% CI=[-0.415, -0.407]\n",
            "BERT-base_layer_04 | agree: GDV_obs=-0.256, Boot mean=-0.262, SD=0.0046, 95% CI=[-0.270, -0.253]\n",
            "BERT-base_layer_04 | come: GDV_obs=-0.191, Boot mean=-0.196, SD=0.0045, 95% CI=[-0.205, -0.187]\n",
            "BERT-base_layer_04 | give: GDV_obs=-0.288, Boot mean=-0.293, SD=0.0041, 95% CI=[-0.301, -0.285]\n",
            "BERT-base_layer_04 | all: GDV_obs=-0.369, Boot mean=-0.373, SD=0.0021, 95% CI=[-0.377, -0.369]\n",
            "BERT-base_layer_05 | agree: GDV_obs=-0.233, Boot mean=-0.238, SD=0.0043, 95% CI=[-0.246, -0.230]\n",
            "BERT-base_layer_05 | come: GDV_obs=-0.133, Boot mean=-0.138, SD=0.0043, 95% CI=[-0.147, -0.130]\n",
            "BERT-base_layer_05 | give: GDV_obs=-0.236, Boot mean=-0.241, SD=0.0037, 95% CI=[-0.249, -0.234]\n",
            "BERT-base_layer_05 | all: GDV_obs=-0.320, Boot mean=-0.324, SD=0.0020, 95% CI=[-0.328, -0.320]\n",
            "BERT-base_layer_06 | agree: GDV_obs=-0.220, Boot mean=-0.225, SD=0.0043, 95% CI=[-0.233, -0.217]\n",
            "BERT-base_layer_06 | come: GDV_obs=-0.102, Boot mean=-0.108, SD=0.0043, 95% CI=[-0.117, -0.100]\n",
            "BERT-base_layer_06 | give: GDV_obs=-0.190, Boot mean=-0.196, SD=0.0034, 95% CI=[-0.203, -0.189]\n",
            "BERT-base_layer_06 | all: GDV_obs=-0.283, Boot mean=-0.287, SD=0.0020, 95% CI=[-0.291, -0.284]\n",
            "BERT-base_layer_07 | agree: GDV_obs=-0.179, Boot mean=-0.184, SD=0.0041, 95% CI=[-0.192, -0.177]\n",
            "BERT-base_layer_07 | come: GDV_obs=-0.083, Boot mean=-0.089, SD=0.0042, 95% CI=[-0.098, -0.081]\n",
            "BERT-base_layer_07 | give: GDV_obs=-0.155, Boot mean=-0.161, SD=0.0032, 95% CI=[-0.167, -0.154]\n",
            "BERT-base_layer_07 | all: GDV_obs=-0.236, Boot mean=-0.241, SD=0.0020, 95% CI=[-0.245, -0.237]\n",
            "BERT-base_layer_08 | agree: GDV_obs=-0.156, Boot mean=-0.161, SD=0.0039, 95% CI=[-0.169, -0.154]\n",
            "BERT-base_layer_08 | come: GDV_obs=-0.070, Boot mean=-0.076, SD=0.0041, 95% CI=[-0.084, -0.068]\n",
            "BERT-base_layer_08 | give: GDV_obs=-0.118, Boot mean=-0.124, SD=0.0030, 95% CI=[-0.130, -0.118]\n",
            "BERT-base_layer_08 | all: GDV_obs=-0.194, Boot mean=-0.200, SD=0.0019, 95% CI=[-0.203, -0.196]\n",
            "BERT-base_layer_09 | agree: GDV_obs=-0.131, Boot mean=-0.137, SD=0.0037, 95% CI=[-0.144, -0.130]\n",
            "BERT-base_layer_09 | come: GDV_obs=-0.058, Boot mean=-0.065, SD=0.0038, 95% CI=[-0.072, -0.057]\n",
            "BERT-base_layer_09 | give: GDV_obs=-0.097, Boot mean=-0.103, SD=0.0028, 95% CI=[-0.109, -0.098]\n",
            "BERT-base_layer_09 | all: GDV_obs=-0.161, Boot mean=-0.167, SD=0.0018, 95% CI=[-0.170, -0.163]\n",
            "BERT-base_layer_10 | agree: GDV_obs=-0.115, Boot mean=-0.121, SD=0.0036, 95% CI=[-0.129, -0.114]\n",
            "BERT-base_layer_10 | come: GDV_obs=-0.055, Boot mean=-0.061, SD=0.0036, 95% CI=[-0.068, -0.054]\n",
            "BERT-base_layer_10 | give: GDV_obs=-0.083, Boot mean=-0.090, SD=0.0025, 95% CI=[-0.094, -0.085]\n",
            "BERT-base_layer_10 | all: GDV_obs=-0.142, Boot mean=-0.148, SD=0.0017, 95% CI=[-0.151, -0.145]\n",
            "BERT-base_layer_11 | agree: GDV_obs=-0.111, Boot mean=-0.117, SD=0.0036, 95% CI=[-0.124, -0.110]\n",
            "BERT-base_layer_11 | come: GDV_obs=-0.052, Boot mean=-0.059, SD=0.0035, 95% CI=[-0.066, -0.052]\n",
            "BERT-base_layer_11 | give: GDV_obs=-0.078, Boot mean=-0.085, SD=0.0024, 95% CI=[-0.089, -0.080]\n",
            "BERT-base_layer_11 | all: GDV_obs=-0.141, Boot mean=-0.146, SD=0.0017, 95% CI=[-0.150, -0.143]\n",
            "BERT-base_layer_12 | agree: GDV_obs=-0.108, Boot mean=-0.114, SD=0.0036, 95% CI=[-0.121, -0.107]\n",
            "BERT-base_layer_12 | come: GDV_obs=-0.048, Boot mean=-0.054, SD=0.0032, 95% CI=[-0.061, -0.048]\n",
            "BERT-base_layer_12 | give: GDV_obs=-0.078, Boot mean=-0.084, SD=0.0025, 95% CI=[-0.089, -0.080]\n",
            "BERT-base_layer_12 | all: GDV_obs=-0.143, Boot mean=-0.149, SD=0.0017, 95% CI=[-0.152, -0.145]\n",
            "\n",
            "✓ Bootstrap CI/SD analysis complete.\n",
            "  - CSV: CxG-BERT_gdv_bootstrap_ci.csv\n",
            "  - Plots: plots_with_ci/ (8 files)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Compress the folder\n",
        "shutil.make_archive('/content/plots_with_ci', 'zip', '/content/plots_with_ci')\n",
        "\n",
        "# Download the zip file\n",
        "from google.colab import files\n",
        "files.download('/content/plots_with_ci.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "T8ZUZW95m7ut",
        "outputId": "e00432ca-2aa9-4958-c21a-80ef7417394a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_174fc56e-3f3c-47c4-8ee7-6e0a6319bc64\", \"plots_with_ci.zip\", 755740)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EnrlfyC7BYns"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}